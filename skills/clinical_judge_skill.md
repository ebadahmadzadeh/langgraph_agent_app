
## Overview
This agent is a clinical judge who receives a patient's medical notes and the insights generated by another agent, and makes an assessment about the accuracy of the insights.

Target Users: Agentic AI developers and medical experts

## Architecture
This agent uses a simplified 2-subskill workflow:
```
Subskill 1: Evaluation of Treatment Plan
  ↓ (analyzes patient notes, the query, and the generated response and makes an assessment)
Subskill 2: Evaluation of Summarization
  ↓ (analyzes patient notes, the query, and the generated response and makes an assessment)
```

## Execution Flow

### Validation
The context must contain a non-empty <documents> tag containing all input data necessary for this skill. Do not call tools to load the input data.

### Subskill 1: Evaluation of Treatment Plan
The goal is to compare the patient's notes (in <notes>), a query describing the task (in <treatment_plan_query>), and the generated response (in <treatment_plan_response>), and assess how accurate the response is.

Assess the following metrics:

**Hallucination**: Any statement or claims present in the generated treatment plan response but not grounded in the patient's notes is considered as a hallucination. Hallucination score is 0 when no such instances are found, and 1 when one or more instances are found.

**Accuracy**: measures how accurately the generated treatment plan response answers the treatment plan query. Report a confidence level (LOW | MEDIUM | HIGH) and create a list of inaccurate or missing facts for reference.

Finally, write a JSON file with the evaluation results using the following schema.
```
{
    "patient_id": "patient_id_value",
    "evaluation_task": "treatment_plan",
    "hallucination": {
        "score": "0 or 1",
        "instances": [
            "one instance of hallucination"
        ]
    },
    "accuracy": {
        "score": "LOW | MEDIUM | HIGH",
        "reason": "reasons for inaccuracy"
    }
}
```

Output JSON file name:
```python
filename = f"pid{patient_id:04d}_eval_treatment_plan.json"
```
Tools:
- json_writer

### Subskill 2: Evaluation of Summarization
The goal is to compare the patient's notes (in <notes>), a query describing the summarization task (in <summarization_query>), the generated summary (in <summarization_response>), and the ground truth response (in <summarization_ground_truth>), and assess how well the generated summary covers the ground truth summary.

Assess the following metrics:

**Hallucination**: Any statement or claims present in the generated summary but not grounded in the patient's notes is considered as a hallucination. Hallucination score is 0 when no such instances are found, and 1 when one or more instances are found.

**Accuracy**: measures how accurately the generated summary (in <summarization_response>) covers the ground truth summary (in <summarization_ground_truth>). Report a confidence level (LOW | MEDIUM | HIGH) and create a list of missing facts for reference.

Finally, write a JSON file with the evaluation results using the following schema.
```
{
    "patient_id": "patient_id_value",
    "evaluation_task": "summarization",
    "hallucination": {
        "score": "0 or 1",
        "instances": [
            "an instance of hallucination"
        ]
    },
    "accuracy": {
        "score": "LOW | MEDIUM | HIGH",
        "reason": "missing facts according to the ground truth summary"
    }
}
```

Output JSON file name:
```python
filename = f"pid{patient_id:04d}_eval_summarization.json"
```
Tools:
- json_writer

Finally, list a concise summary of the work done.